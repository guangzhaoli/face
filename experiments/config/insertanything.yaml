flux_fill_path: "model/flux_fill"
flux_redux_path: "model/flux_redux"
dtype: "bfloat16"

model:
  union_cond_attn: true
  add_cond_attn: false
  latent_lora: false
  use_t_aware_weighting: true

  # Face Identity Loss (ArcFace-based)
  use_face_loss: true
  use_multiscale_face_loss: true
  face_loss_weight: 0.5
  multiscale_layer_weights:
    layer1: 0.1
    layer2: 0.2
    layer3: 0.3
    layer4: 0.4
    embedding: 1.0
  arcface_model: "r100"
  face_align_mode: "kps"
  arcface_weights: "model/arcface/backbone.pth"

  # LPIPS Perceptual Loss
  use_lpips_loss: true
  lpips_loss_weight: 0.1
  lpips_net: "vgg"
  lpips_weights: "model/lpips/vgg.pth"

  # SSIM Structural Similarity Loss
  use_ssim_loss: true
  ssim_loss_weight: 0.1
  ssim_window_size: 11

  # Mask-weighted MSE Loss (prioritize edited regions)
  use_mask_weighted_loss: false
  mask_region_weight: 2.0
  background_region_weight: 1.0

train:
  batch_size: 8
  accumulate_grad_batches: 1
  dataloader_workers: 16
  # pin_memory: false
  save_interval: 500
  sample_interval: 500
  max_steps: -1
  gradient_checkpointing: true
  save_path: "runs"
  tensorboard:
    enabled: true
    log_interval: 10

  lora_config:
    r: 256
    lora_alpha: 256
    init_lora_weights: "gaussian"
    target_modules: "(.*x_embedder|.*(?<!single_)transformer_blocks\\.[0-9]+\\.norm1\\.linear|.*(?<!single_)transformer_blocks\\.[0-9]+\\.attn\\.to_k|.*(?<!single_)transformer_blocks\\.[0-9]+\\.attn\\.to_q|.*(?<!single_)transformer_blocks\\.[0-9]+\\.attn\\.to_v|.*(?<!single_)transformer_blocks\\.[0-9]+\\.attn\\.to_out\\.0|.*(?<!single_)transformer_blocks\\.[0-9]+\\.ff\\.net\\.2|.*single_transformer_blocks\\.[0-9]+\\.norm\\.linear|.*single_transformer_blocks\\.[0-9]+\\.proj_mlp|.*single_transformer_blocks\\.[0-9]+\\.proj_out|.*single_transformer_blocks\\.[0-9]+\\.attn.to_k|.*single_transformer_blocks\\.[0-9]+\\.attn.to_q|.*single_transformer_blocks\\.[0-9]+\\.attn.to_v|.*single_transformer_blocks\\.[0-9]+\\.attn.to_out)"

  optimizer:
    type: "Prodigy"
    params:
      lr: 1
      use_bias_correction: true
      safeguard_warmup: true
      weight_decay: 0.01
